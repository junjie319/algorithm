#### **数据库**

##### **索引B+树**

为什么说B+树比B树更适合数据库索引？

- B+树的磁盘读写代价更低。**B+树的内部没有指向关键字具体信息的指针**，所以其内部节点相对B树更小，如果把所有关键字存放在同一块盘中，那么盘中所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，**相应的，IO读写次数就降低了**。
- **树的查询效率更加稳定**。B+树所有数据都存在于叶子节点，所有关键字查询的路径长度相同，每次数据的查询效率相当。而B树可能在非叶子节点就停止查找了，所以查询效率不够稳定。
- **B+树只需要去遍历叶子节点就可以实现整棵树的遍历**。

PS：

数据库索引采用B+树的主要原因是：B树在提高了IO性能的同时并没有解决元素遍历效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低。

![b+tree](https://github.com/junjie319/algorithm/blob/main/IMG/b+tree.png?raw=true)



##### **数据库事物级别**

InnoDB 存储引擎中的事务完全符合ACID 的特性。 
原子性 （atomicity） 一致性（consistency） 隔离性（isolation） 持久性（durability）

SQL 标准定义的四个隔离级别为: 

| 隔离级别         | 脏读   | 不可重复读 | 幻读   |
| ---------------- | ------ | ---------- | ------ |
| READ UNCOMMITTED | 可能   | 可能       | 可能   |
| READ COMMITED    | 不可能 | 可能       | 可能   |
| REPEATABLE READ  | 不可能 | 不可能     | 可能   |
| SERIALIZABLE     | 不可能 | 不可能     | 不可能 |

  **脏读:** 又称无效数据的读出，是指在数据库访问中，事务T1将某一值修改，然后事务T2读取该值，此后T1因为某种原因撤销对该值的修改，这就导致了T2所读取到的数据是无效的。

 **不可重复读**：是指在数据库访问中，一个事务范围内两个相同的查询却返回了不同数据（T2对数据进行了update）

 **幻读：** 是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的“全部数据行”。同时，第二个事务也修改这个表中的数据，这种`修改是向表中插入“一行新数据”`。

**不可能重复读和幻读的区别：** 
很多人容易搞混不可重复读和幻读，确实这两者有些相似。但不可重复读重点在于update和delete，而幻读的重点在于insert。

##### **事物的实现**

事务的隔离性由锁来实现。redo log 称为重做日志，用来保证事务的原子性和持久性。 undo log 用来保证事务的一致性，用来帮助事务回滚及多版本控制（mvcc）的功能。

为了确保每次日志都写入重做日志文件，在每次都将重做日志缓冲写入重做日志文件后，InnoDB存储引擎都需要调用一次fsync 操作。innodb_flush_log_at_trx_commit 1 ： 表示每个事务提交时进行写入到重做日志。

##### **MVCC**

Multi-Version Concurrency Control，多版本并发控制。 就是同一份数据临时保留多版本的一种方式，进而实现并发控制。通过数据行的版本号 （DB_TRX_ID）、删除版本号 (DB_ROLL_PT)

##### **乐观锁和悲观锁**

（乐观锁，假定别人不会修改，等到需要更新的时候再去判断数据是否做过更新；悲观锁假定每一次都被改的）乐观锁常用版本号机制和cas算法（需要读写的值v，进行比较的值a，准备写入的值b）；

与悲观并发控制和乐观并发控制不同的是，MVCC是为了解决读写锁造成的多个、长时间的读操作饿死写操作问题，也就是解决读写冲突的问题。MVCC 可以与前两者中的任意一种机制结合使用，以提高数据库的读性能。

##### **行锁优化**

1 尽可能让所有数据检索都通过索引来完成，避免无索引行或索引失效导致行锁升级为表锁。

2 尽可能避免间隙锁带来的性能下降，减少或使用合理的检索范围。

3 尽可能减少事务的粒度，比如控制事务大小，而从减少锁定资源量和时间长度，从而减少锁的竞争等，提供性能。

4 尽可能低级别事务隔离，隔离级别越高，并发的处理能力越低。

##### **锁总结**

1 InnoDB 支持表锁和行锁，使用索引作为检索条件修改数据时采用行锁，否则采用表锁。

2 InnoDB 自动给修改操作加锁，给查询操作不自动加锁

3 行锁可能因为未使用索引而升级为表锁，所以除了检查索引是否创建的同时，也需要通过explain执行计划查询索引是否被实际使用。

4 行锁相对于表锁来说，优势在于高并发场景下表现更突出，毕竟锁的粒度小。

5 当表的大部分数据需要被修改，或者是多表复杂关联查询时，建议使用表锁优于行锁。

6 为了保证数据的一致完整性，任何一个数据库都存在锁定机制。锁定机制的优劣直接影响到一个数据库的并发处理能力和性能。

##### **慢查询原因及避免**

1.网络原因

2.索引失效： 模糊匹配、类型隐转、最左匹配，这三种情况可能导致索引会失效。

避免：应尽量避免在 where 子句中对字段进行 null 值判断；避免在 where 子句中使用!=或<>操作符；

like %keyword  索引失效，like keyword%  索引生效；

##### **delete/drop/truncate**

| delete                | truncate            | drop                |
| --------------------- | ------------------- | ------------------- |
| 删数据                | 删数据              | 删数据及表结构      |
| DML事物提交生效可回滚 | DDL立即生效不可回滚 | DDL立即生效不可回滚 |



#### **计网**

##### **get和post的区别**

（参数位置、参数长度限制[无差异,是浏览器及服务器限定]、参数编码样式、浏览器结合（get会主动缓存且返回无害）

**GET 和 POST 方法没有实质区别**，只是报文格式不同。GET 和 POST 只是 HTTP 协议中两种请求方式，而 HTTP 协议是基于 TCP/IP 的应用层协议，无论 GET 还是 POST，用的都是同一个传输层协议，所以在传输上，没有区别。

##### **输入一个url过程**

-url输入、dns解析找到ip（先DNS由底向上查找缓存）、tcp连接建立（三次握手）、发送http请求、服务端处理请求并返回（状态码：1xx：指示信息–表示请求已接收，继续处理。2xx：成功–表示请求已被成功接收、理解、接受。3xx：重定向–要完成请求必须进行更进一步的操作。4xx：客户端错误–请求有语法错误或请求无法实现。5xx：服务器端错误–服务器未能实现合法的请求。）、浏览器解析资源、渲染、tcp连接关闭（四次挥手）。

##### **状态码及解决**

403-Forbidden

原因：禁止访问，请求是合法的，权限校验不通过。

502 Bad Gateway

原因：网关错误，当前链接过多，一般是服务器作为代理服务器请求后端的服务器时，后端的服务不可用或没有完成响应给网关服务器，一般为反向代理服务器后端的服务器节点出现故障。

解决：检查代理服务器后端的服务器是否正常运行，重启apache。

503-Service Unavailable

原因：服务当前不可用，可能是因为服务器超载或停机维护导致，或者是反向代理服务器后面没有可以提供服务的节点。

解决：服务器共供应商可能正在维护或者暂停服务，你可以联系一下服务器供应商；还有可能就是服务器的cpu或内存占用过高，需要清理一下资源，必要时重启服务器。

504-Gateway Timeout

原因：网关超时，一般是网关代理服务器请求后端服务器或者cdn请求源站服务器时，服务器没有在特定的时间处理并相应请求，一般为服务器过载，没有在指定时间返回服数据。

解决：对服务器性能参数进行相关调整，包括php参数调整，数据库参数调整，web服务器参数调整；必要时可以选择升级服务器配置。

##### **三次握手**

：client send->svr request->client confirm(建立链接，进入ESTABLISHED状态)

- 客户端发送一个带 SYN=1，Seq=X 的数据包到服务器端口（第一次握手，由浏览器发起，告诉服务器我要发送请求了）
- 服务器发回一个带 SYN=1， ACK=X+1， Seq=Y 的响应包以示传达确认信息（第二次握手，由服务器发起，告诉浏览器我准备接受了，你赶紧发送吧）
- 客户端再回传一个带 ACK=Y+1， Seq=Z 的数据包，代表“握手结束”（第三次握手，由浏览器发送，告诉服务器，我马上就发了，准备接受吧）

##### **四次挥手**

- 发起方向被动方发送报文，Fin、Ack、Seq，表示已经没有数据传输了。并进入 FIN_WAIT_1 状态。(第一次挥手：由浏览器发起的，发送给服务器，我请求报文发送完了，你准备关闭吧)
- 被动方发送报文，Ack、Seq，表示同意关闭请求。此时主机发起方进入 FIN_WAIT_2 状态。(第二次挥手：由服务器发起的，告诉浏览器，我请求报文接受完了，我准备关闭了，你也准备吧)
- 被动方向发起方发送报文段，Fin、Ack、Seq，请求关闭连接。并进入 LAST_ACK 状态。(第三次挥手：由服务器发起，告诉浏览器，我响应报文发送完了，你准备关闭吧)
- 发起方向被动方发送报文段，Ack、Seq。然后进入等待 TIME_WAIT 状态。被动方收到发起方的报文段以后关闭连接。发起方等待一定时间未收到回复，则正常关闭。(第四次挥手：由浏览器发起，告诉服务器，我响应报文接受完了，我准备关闭了，你也准备吧)

svr/client均可主动关闭连接，举例client主动关闭

client send close->svr ready(确认收到请求准备关闭，进入CLOSE_WAIT状态)->svr ready(svr已准备好关闭没确认)->client confirm(client收到svr确认，发送确认包，进入TIME_WAIT状态)

发起socket主动关闭的一方 socket将进入TIME_WAIT状态，TIME_WAIT状态将持续2个MSL(Max Segment Lifetime),在Windows下默认为4分钟，即240秒。

TIME_WAIT原因：1、保证TCP协议的全双工连接能够可靠关闭（直接关闭，如果网络原因导致svr没收到确认，就会视为错误上报）；2、保证这次连接的重复数据段从网络中消失（直接关闭后发起新链接，端口一致，可能导致上次的延迟数据到新svr，导致数据混淆）

##### **Cookies和Session**

由于http的无状态性，为了使某个域名下的所有网页能够共享某些数据，session和cookie出现了。客户端访问服务器的流程如下：首先，客户端会发送一个http请求到服务器端。服务器端接受客户端请求后，建立一个session，并发送一个http响应到客户端，这个响应头，其中就包含Set-Cookie头部。该头部包含了sessionId。在客户端发起的第二次请求，假如服务器给了set-Cookie，浏览器会自动在请求头中添加cookie；服务器接收请求，分解cookie，验证信息，核对成功后返回response给客户端

- cookie只是实现session的其中一种方案。虽然是最常用的，但并不是唯一的方法。禁用cookie后还有其他方法存储，比如放在url中

- 现在大多都是Session + Cookie，但是只用session不用cookie，或是只用cookie，不用session在理论上都可以保持会话状态。可是实际中因为多种原因，一般不会单独使用

- 用session只需要在客户端保存一个id，实际上大量数据都是保存在服务端。如果全部用cookie，数据量大的时候客户端是没有那么多空间的。

- 如果只用cookie不用session，那么账户信息全部保存在客户端，一旦被劫持，全部信息都会泄露。并且客户端数据量变大，网络传输的数据量也会变大

- session存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号sessionId，通常存放于cookie中。服务器收到cookie后解析出sessionId，再去session列表中查找，才能找到相应session。依赖cookie

- cookie类似一个令牌，装有sessionId，存储在客户端，浏览器通常会自动添加。

  

##### **OSI七层模型与TCP/IP**

![b+tree](https://github.com/junjie319/algorithm/blob/main/IMG/OSI.png?raw=true)

#### **Java GC**

##### **对象是否死亡?**

1.引用计数法：给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的，很难解决对象之间相互循环引用的问题。

2.可达性分析法：“GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。“GC Roots：虚拟机栈(栈帧中的本地变量表)中引用的对象、本地方法栈(Native 方法)中引用的对象、方法区中类静态属性引用的对象、方法区中常量引用的对象

##### **分代垃圾收集算法**

所以 Java 堆还可以细分为：新生代和老年代，根据各个年代的特点选择合适的垃圾收集算法。比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。

##### **不可达对象并非非死**

可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize 方法。当对象没有覆盖 finalize 方法，或 finalize 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。

##### **引用**

强引用：垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止

软银用：如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用

在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为**软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生**。

##### HashMap/HashTable/ConcurrentHashMap

| 集合              | key允许为`null` | **value允许为**`null` | **线程安全** | **同步机制**                    |
| ----------------- | --------------- | --------------------- | ------------ | ------------------------------- |
| HashMap           | 是              | 是                    | 否           | 无                              |
| HashTable         | 否              | 否                    | 是           | synchronized                    |
| ConcurrentHashMap | 否              | 否                    | 是           | lock，java8之后改为synchronized |

HashTable虽然是线程安全，但是是通过synchronized机制做了简单的实现，无论搜索和操作的时候都是对整理哈希表锁定，比较影响性能。ConcurrentHashMap的提出就是为了解决这个问题。不同于HashTable，ConcurrentHashMap是通过Segment(分段锁16段)进行分隔从而只是锁住哈希表的一部分，提高性能，这也是两者的主要区别。

##### **hashmap怎么解决hash冲突**

链表法和开放地址法。链表法就是将相同hash值的对象组织成一个链表放在hash值对应的槽位；开放地址法是通过一个探测算法，当某个槽位已经被占据的情况下继续查找下一个可以使用的槽位。

#### **REDIS**

##### **Redis支持的数据类型**  

string list hash set zset（基本回答）  注意： redis5.x之后加了Stream（流）数据类型，所以5.x之后一共是6种数据类型
加分项：另外redis还对这几种数据类型做了扩展，如GEO对位置计算，hyperLogLog做统计，bitmaps：redis底层存储value值都是存储的二进制数据，redis提供bitmaps（位图）可以直接访问或修改底层存储的二进制数据
string list hash set zset Strea是数据类型
hyperLogLog GEO bitmaps等都是基于上面的数据类型扩展的数据结构，请注意数据类型和数据结构

##### **Redis 提供的持久机制**

redis 支持rdb和aof两种持久机制,redis4.0后支持混合持久化。rdb是定时的持久机制，宕机有可能会丢失最后一次持久化之后存在数据丢失。aof是基于操作日志追加的持久机制。（基本回答）
1).rdb持久化原理
原理是redis会单独创建（fork）一个与当前进程一模一样的子进程来进行持久化，这个子线程的所有数据（变量。环境变量，程序程序计数器等）都和原进程一模一样，会先将数据写入到一个临时文件中，待持久化结束了，再用这个临时文件替换上次持久化好的文件
2).他什么时候fork子进程，或者什么时候触发rdb持久化机制
 shutdown时，如果没有开启aof，会触发 配置文件中默认的快照配置; 执行命令save或者bgsave  save是只管保存，其他不管，全部阻塞   bgsave： redis会在后台异步进行快照操作，同时可以响应客户端的请求，但是在调用fork函数时是阻塞的，很快，可以忽略不计

3).aof原理及触发机制（根据配置文件配置项）
原理是将Reids的操作日志以追加的方式写入文件，读操作是不记录的
no：表示等操作系统进行数据缓存同步到磁盘（快，持久化没保证）
always：同步持久化，每次发生数据变更时，立即记录到磁盘（慢，安全）
everysec：表示每秒同步一次（默认值,很快，但可能会丢失一秒以内的数据）

##### **缓存穿透**

缓存穿透指的是使用不存在的key进行大量的高并发查询，这导致缓存无法命中，每次请求都要穿透到后端数据库系统进行查询，数据库压力过大。

常用解决方案：将空值缓存起来，缓存时间设置短一点，或者该key对应的数据insert了之后清理缓存。

其他解决方案：使用布隆过滤器（guava 19开始已支持布隆过滤器） 备注：如果你可以理解基于redis位图自己实现的布隆过滤器，可以说说，更加分

##### **缓存雪崩**

当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，会给后端系统带来很大压力。导致系统崩溃。

解决方案：1.主要就是要搭建高可用集群，保证机器的高可用。
2.对不同的数据使用不同的失效时间，甚至对相同的数据、不同的请求使用不同的失效时间。
如果线上环境出现了雪崩（解决方案）

#### **多线程&多进程**

进程是CPU资源分配的最小单位；线程是CPU调度的最小单位；

##### **线程同步**

synchronized 关键字

wait、notify等

Concurrent包中的`ReentrantLock`

volatile关键字

保证可见行（某线程改变了主内存变量要保证其他线程可见），不保证原子性，禁止指令重排

ThreadLocal局部变量

生产者、消费者是wait、notify最典型的应用场景，这些函数的调用，是必须要放在synchronized代码块里才能够正常运行的。

使用ReentrantLock最容易发生错误的就是忘记在finally代码块里关闭锁。大多数同步场景下，使用Lock就足够了，而且它还有读写锁的概念进行粒度上的控制。我们一般都使用非公平锁，让任务自由竞争。非公平锁性能高于公平锁性能，非公平锁能更充分的利用cpu的时间片，尽量的减少cpu空闲的状态时间。非公平锁还会造成饿死现象：有些任务一直获取不到锁。

volatile总是能保证变量的读可见，但它的目标是基本类型和它锁的基本对象。假如是它修饰的是集合类，比如Map，那么它保证的读可见是map的引用，而不是map对象，这点一定要注意。

ThreadLocal很方便，每个线程一份数据，也很安全，但要注意内存泄露。假如线程存活时间长，我们要保证每次使用完ThreadLocal，都调用它的remove()方法（具体来说是expungeStaleEntry），来清除数据。

##### **线程池**

concurrent包最常用的就是线程池，平常工作建议直接使用线程池，Thread类就可以降低优先级了。我们常用的主要有newSingleThreadExecutor（创建一个单线程的线程池）、newFixedThreadPool（创建固定大小的线程池，每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小）、newCachedThreadPool（创建一个可缓存的线程池）、调度等，使用Executors工厂类创建。底层ThreadPoolExecutor；生产中一般都不使用，而是自定义；

如何合理配置线程数：

1.CPU密集型：应配置尽可能少的线程数，一般：cpu核数+1个线程的线程池；

2.IO密集型：1）根据测试数据压测；2）存在大量俎塞，需要多配置线程数，俎塞系数（线程花在系统IO上的时间与CPU密集任务所耗的时间比值0.8-0.9之间）

参考公式：CPU核数/1-俎塞系数：8核 8/1-0.9=80

七大参数：：

~~~java
public ThreadPoolExecutor(int corePoolSize,
int maximumPoolSize,
long keepAliveTime,
TimeUnit unit,
BlockingQueue<Runnable> workQueue,
ThreadFactory threadFactory,
RejectedExecutionHandler handler) 
~~~

参数1.corePoolSize，2.maximumPoolSize一般都设成一样大的，然后3.keepAliveTime存活时间设的特别的长。可以避免线程频繁创建、关闭的开销。I/O密集型和CPU密集型的应用线程开的大小是不一样的，一般I/O密集型的应用线程就可以开的多一些。

4.工作队列workQueue 工作队列根据需求使用：①ArrayBlockingQueue基于数组的有界阻塞队列，按FIFO排序；②LinkedBlockingQuene基于链表的无界阻塞队列（其实最大容量为Interger.MAX），按照FIFO排序；③SynchronousQuene一个不缓存任务的阻塞队列，生产者放入一个任务必须等到消费者取出这个任务；④PriorityBlockingQueue具有优先级的无界阻塞队列，优先级通过参数Comparator实现。5.线程名threadFactory我一般也会定义一个，主要是给线程们起一个名字。这样，在使用jstack等一些工具的时候，能够直观的看到我所创建的线程。6.handler 拒绝策略：

~~~java
ThreadPoolExecutor.AbortPolicy（默认）:丢弃任务并抛出RejectedExecutionException异常。
ThreadPoolExecutor.DiscardPolicy：丢弃任务，但是不抛出异常。
ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新提交被拒绝的任务
ThreadPoolExecutor.CallerRunsPolicy：由调用线程（提交任务的线程）处理该任务
~~~

监控：高并发下的线程池，最好能够监控起来。可以使用日志、存储等方式保存下来，对后续的问题排查帮助很大。通常，可以通过继承ThreadPoolExecutor，覆盖beforeExecute、afterExecute、terminated方法，达到对线程行为的控制和监控。

##### **CAS**

CAS，全称为Compare and Swap，即比较-替换。假设有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时，才会将内存值修改为B并返回true，否则什么都不做并返回false。当然CAS一定要volatile变量配合，这样才能保证每次拿到的变量是主内存中最新的那个值，否则旧的预期值A对某条线程来说，永远是一个不会变的值A，只要某次CAS操作失败，永远都不可能成功

底层通过unsafe类实现原子操作，属于cpu原子指令，无需使用synchronized就能保证线程安全，乐观锁原理，如果失败则while循环再比较直到成功。

缺点：自旋带来的cpu开销；只能保证一个共享变量的原子操作；ABA问题

ABA：快速线程修改主内存a->b->a，慢线程不知道，时间差导致数据有变化；版本号方式解决aba问题，JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。如果当前引用 == 预期引用，并且当前标志等于预期标志，则以原子方式将该引用和该标志的值设置为给定的更新值。

##### **AQS**

Java中的大部分同步类（Lock、Semaphore、ReentrantLock等）都是基于AbstractQueuedSynchronizer（简称为AQS）实现的。AQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架。

![aqs原理](https://github.com/junjie319/algorithm/blob/main/IMG/AQS%E5%8E%9F%E7%90%86.png?raw=true)

##### **ReentrantLock&Synchronized**

仅当`synchronized`不能满足时才使用`ReentrantLock`，因为使用`ReentrantLock`要非常小心，不释放锁将影响其他需要该锁的代码块运行。

1.Synchronized是jvm实现，`ReentrantLock`是API实现；2.`ReentrantLock`等待可中断；3.`ReentrantLock`锁需要手动释放；

4.Synchronized非公平锁；5.`ReentrantLock`锁可以绑定多个条件Condition，用来实现分组唤醒需要的线程s，可以精确唤醒，Synchronzied只可以随机唤醒一个或者唤醒全部；

![锁对比](https://github.com/junjie319/algorithm/blob/main/IMG/%E9%94%81%E5%AF%B9%E6%AF%94.png?raw=true)

#### **Linux**

cpu占用过高故障排查java：

1.top找出cpu占比过高进程	2.ps -ef | grep xxx得到线程tid	3.ps -mp 进程id -o 线程tid	

4.线程id转换成16进制	5.jstack 进程id ｜ grep tid得到堆栈信息

grep -iA 10 "excepton" php_exception_2020-12-10.log //输出所有excepton后十行

history 10 | awk '{print $2}' //筛选第二列的内容

sed 's/TEST/test/' test.sh //TEST替换成test

sed -n '3,4p' test.sh   //显示文件三四行

cat file1.txt file2.txt > file.txt  //合并文件

cat file1.txt >> file2.txt  //将file1.txt追加到file2.txt的末尾

cat log.log | grep "abc"   //搜索日之下含abc行

ps -aux; top //查看进程

netstat -at  //列出tcp端口

#### **DB CMD**

select distinct ename from wk_projectset;	//查找ename 不重复数据

SELECT * from chengji1 GROUP BY `name` HAVING MIN(chengji)>=85 //每科成绩都大于85